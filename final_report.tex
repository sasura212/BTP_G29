% Fixed LaTeX file (cleaned up to compile with pdflatex/xelatex)
% I made minimal changes to preserve the content while fixing syntax, structure, and missing items.
\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{verbatim} % for verbatim blocks
\usepackage{caption}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Optimal PWM Control of Dual Active Bridge Converters for Electric Vehicle Charging Applications}

\author{\IEEEauthorblockN{Harshit Singh}
\IEEEauthorblockA{\textit{Department of Electrical Engineering} \\
\textit{IIT Roorkee}\\
Roorkee, India \\
22115065 \\
harshit\_s@ee.iitr.ac.in}
\and
\IEEEauthorblockN{Jatin Singal}
\IEEEauthorblockA{\textit{Department of Electrical Engineering} \\
\textit{IIT Roorkee}\\
Roorkee, India \\
22115074 \\
jatin\_s@ee.iitr.ac.in}
\and
\IEEEauthorblockN{Karthik Ayangar}
\IEEEauthorblockA{\textit{Department of Electrical Engineering} \\
\textit{IIT Roorkee}\\
Roorkee, India \\
22115080 \\
karthik\_a@ee.iitr.ac.in}
}

\maketitle

\begin{abstract}
This final report presents the complete implementation of an optimal Triple Phase-Shift (TPS) control system for Dual Active Bridge (DAB) converters in electric vehicle (EV) charging applications. We have successfully developed: (1) a comprehensive multi-mode optimization algorithm generating 91 optimal operating points across 100--1000~W with $<$2~W power error, (2) dual machine learning models—Random Forest and Support Vector Regression (SVR)—for real-time parameter prediction, and (3) an interactive web-based dashboard with model comparison capabilities. The Random Forest achieves Test R$^2$ = 0.985 for $I_{rms}$ prediction, while SVR demonstrates superior $D_2$ accuracy (R$^2$ = 0.930 vs 0.589) with 200 times smaller model size, enabling efficient deployment across variable load conditions in EV charging infrastructure.
\end{abstract}

\begin{IEEEkeywords}
Dual Active Bridge (DAB), Triple Phase-Shift Control, Machine Learning, Random Forest, Support Vector Regression, Electric Vehicle Charging, Real-Time Optimization, Interactive Dashboard, Current Stress Minimization.
\end{IEEEkeywords}

\section{Introduction}

The mid-term evaluation report established the theoretical foundation for optimal PWM control of DAB converters under variable load conditions. This final report documents the complete system implementation, from optimization algorithms to machine learning integration and user interface deployment.

Electric vehicle charging stations face the challenge of operating efficiently across a wide and unpredictable power range due to varying battery states, vehicle types, and dynamic power allocation strategies. Traditional fixed-parameter control approaches fail to maintain high efficiency under such conditions. Our implementation addresses this challenge through exhaustive multi-mode optimization, dual machine learning models (Random Forest and SVR) with complementary strengths, and an interactive dashboard enabling real-time model comparison and parameter prediction.

\section{System Specifications and Design Parameters}

The implemented system is based on a 2-level DAB converter with the following specifications:

\begin{itemize}
    \item \textbf{Primary DC Voltage ($V_1$):} 200~V
    \item \textbf{Secondary DC Voltage ($V_2$):} 50~V (reflected to primary side)
    \item \textbf{Series Inductance ($L$):} 20~$\mu$H
    \item \textbf{Switching Frequency ($f$):} 50~kHz
    \item \textbf{Half Switching Period ($T$):} 10~$\mu$s
    \item \textbf{Power Range:} 100 -- 1000~W
    \item \textbf{Operating Modes:} 1, 2, 3, 4, 5, 6 (as per Tong et~al. \cite{b1})
\end{itemize}

The control variables are the phase-shift parameters $D_0$ (external phase shift), $D_1$ (primary bridge internal phase shift), and $D_2$ (secondary bridge internal phase shift), all normalized to the half-period $T$ and constrained to the range $[0.01, 0.99]$.

\section{Multi-Mode Optimization Framework}

\subsection{Analytical Model Implementation}

The analytical model presented by Tong et~al. \cite{b1} divides DAB operation into six distinct modes based on the relative timing of switching events. Each mode has specific validity constraints, power transfer equations, and RMS current expressions. We implemented all six modes in Python, translating the mathematical formulations into computational algorithms.

\textbf{Mode Constraint Functions:} Each mode's operating region is defined by inequality constraints on $D_0$, $D_1$, and $D_2$. For example:
\begin{itemize}
    \item Mode 1: $D_1 < D_0$, $D_1 < D_0 + D_2$, $D_0 + D_2 < 1$
    \item Mode 2: $D_1 < D_0$, $1 < D_0 + D_2 < 1 + D_1$
    \item Mode 3: $D_1 < D_0$, $1 + D_1 < D_0 + D_2 < 2$
    \item Mode 4: $D_0 < D_1$, $0 < D_0 + D_2 < D_1$
    \item Mode 5: $D_0 < D_1$, $D_1 < D_0 + D_2 < 1$
    \item Mode 6: $D_0 < D_1$, $1 < D_0 + D_2 < 1 + D_1$
\end{itemize}

Similar constraint functions were implemented for Modes 3, 4, 5, and 6 using Boolean logic in Python:

\begin{verbatim}
def is_mode5_valid(D0, D1, D2):
    return (D0 < D1 and 
            D1 < D0 + D2 and 
            D0 + D2 < 1)
\end{verbatim}

\textbf{Power Equations:} Each mode has a unique power transfer equation implemented as a Python function. For instance, Mode 1 power is given by:
\begin{multline}
P_1 = \frac{-V_1 V_2 T}{L}(-D_0 + D_0^2 + 0.5 D_1 - D_0 D_1 \\
+ 0.5 D_1^2 - 0.5 D_2 + D_0 D_2 - 0.5 D_1 D_2 + 0.5 D_2^2)
\end{multline}

Implemented as:
\begin{verbatim}
def power_mode1(D0, D1, D2, V1, V2, 
                L, T):
    return (-V1*V2*T/L) * (
        -D0 + D0**2 + 0.5*D1 - D0*D1
        + 0.5*D1**2 - 0.5*D2 + D0*D2
        - 0.5*D1*D2 + 0.5*D2**2
    )
\end{verbatim}

\textbf{$I_{rms}$ Calculation:} The RMS current for each mode is computed using detailed piecewise integration of the triangular inductor current waveform. The general form involves terms like:
\begin{multline}
I_{rms}^2 = \frac{T^2}{3 L^2} \left[0.125 V_1^2 + 0.125 V_2^2 \right. \\
\left. + f(D_0, D_1, D_2, V_1, V_2)\right]
\end{multline}
where $f(\cdot)$ contains mode-specific polynomial terms. Mode 1's implementation spans 15 lines of code with 20+ polynomial terms, carefully transcribed from the paper to ensure mathematical accuracy.

\subsection{Integrated Optimization Algorithm}

Rather than relying on gradient-based optimization (which can get trapped in local minima), we implemented an exhaustive grid search algorithm that explores all valid operating points across all modes simultaneously.

\textbf{Algorithm Overview:}
\begin{enumerate}
    \item \textbf{Grid Generation:} Create a 3D grid of candidate points:
    \begin{itemize}
        \item $D_0 \in [0.01, 0.99]$, step = 0.01
        \item $D_1 \in [0.01, 0.99]$, step = 0.01
        \item $D_2 \in [0.01, 0.99]$, step = 0.01
        \item Total search space: $99^3 \approx 970,299$ points
    \end{itemize}
    
    \item \textbf{Multi-Mode Evaluation:} For each grid point $(D_0, D_1, D_2)$:
    \begin{itemize}
        \item Check validity against all 5 mode constraints
        \item For each valid mode, compute: $P_{mode}(D_0, D_1, D_2)$ and $I_{rms,mode}(D_0, D_1, D_2)$
        \item Filter points where $|P_{computed} - P_{target}| < \epsilon$ (power tolerance)
    \end{itemize}
    
    \item \textbf{Global Optimization:} Among all valid points that satisfy the power constraint:
    \begin{itemize}
        \item Select the point with minimum $I_{rms}$
        \item Record the corresponding mode, $D_0$, $D_1$, $D_2$, and $I_{rms}$
    \end{itemize}
    
    \item \textbf{Lookup Table Generation:} Repeat for $P_{target} = 100, 110, 120, \ldots, 1000$~W
\end{enumerate}

\textbf{Implementation Details:} The core optimization logic is structured as follows:

\begin{verbatim}
d_range = np.arange(0.01, 1.0, 0.01)
grid = np.array(np.meshgrid(
    d_range, d_range, d_range
)).T.reshape(-1, 3)

best_irms = float('inf')
best_params = None

for d0, d1, d2 in grid:
    for mode in [1, 2, 3, 4, 6]:
        if is_valid(mode, d0, d1, d2):
            P = power_eq[mode](d0,d1,d2)
            if abs(P - P_target) < tol:
                irms = irms_eq[mode](
                    d0, d1, d2)
                if irms < best_irms:
                    best_irms = irms
                    best_params = (mode, 
                        d0, d1, d2)
\end{verbatim}

\textbf{Computational Efficiency:} The algorithm processes approximately 2~seconds per power point on modern hardware, with progress tracking via \texttt{tqdm}. Vectorization using NumPy arrays reduces inner loop overhead. The fine resolution (step\_size = 0.01) ensures high accuracy, achieving power errors consistently below 2~W.

\subsection{Optimization Results}

The integrated optimizer successfully generated a comprehensive lookup table with 91 optimal operating points:

\begin{table}[htbp]
\caption{Optimization Performance Summary}
\centering
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Number of Power Points & 91 \\
Power Range & 100 -- 1000~W \\
Power Step Size & 10~W \\
Grid Resolution & 0.01 \\
Average Power Error & 1.19~W \\
Maximum Power Error & 1.99~W \\
Power Tolerance & 2.0~W \\
Computation Time & $\sim$180~seconds \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Findings:}
\begin{itemize}
    \item \textbf{Mode Distribution:} Different power levels select different optimal modes (Fig.\ref{fig_optimization}). Low power (100--130~W) uses Mode 3; higher powers utilize Modes 1, 2, 5, and 6.
    \item \textbf{Superiority Over Gradient Methods:} At 100~W, exhaustive search found $I_{rms}=0.086$~A vs SLSQP's 7.39~A—an 85.9\times improvement.
    \item \textbf{Accuracy:} All 91 points achieve power delivery within $\pm$2~W of target (mean error: 1.19~W).
\end{itemize}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{optimization_results.png}
\caption{Optimal duty cycles and $I_{rms}$ vs power across all operating modes. The fine grid resolution captures mode transitions and achieves consistent power accuracy $<$2~W.}
\label{fig_optimization}
\end{figure}

\section{Machine Learning Implementation}

\subsection{Dual-Model Approach}

We implemented two complementary machine learning algorithms to predict TPS parameters from target power:

\textbf{Random Forest Regressor:} An ensemble method combining 300 decision trees with bootstrap aggregation. Each tree independently predicts all four outputs ($D_0$, $D_1$, $D_2$, $I_{rms}$), and predictions are averaged for robustness. The implementation uses scikit-learn's \texttt{RandomForestRegressor} with default parameters:

\begin{verbatim}
from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor(
    n_estimators=300,
    random_state=42,
    n_jobs=-1
)
model.fit(X_train, y_train)
\end{verbatim}

Random Forest requires no feature scaling and handles non-linear relationships naturally through recursive partitioning.

\textbf{Support Vector Regression (SVR):} Four separate SVR models were trained for each output parameter using the Radial Basis Function (RBF) kernel, which excels at smooth interpolation:

\begin{verbatim}
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)

svr_models = {}
for output in ['D0', 'D1', 'D2', 'Irms_A']:
    svr = SVR(kernel='rbf', C=100, 
              gamma=0.1, epsilon=0.001)
    svr.fit(X_scaled, y_train[output])
    svr_models[output] = svr
\end{verbatim}

The hyperparameters were selected based on grid search: $C=100$ (regularization), $\gamma=0.1$ (RBF bandwidth), $\epsilon=0.001$ (tube width). Feature scaling via \texttt{StandardScaler} is critical for SVR performance.

\subsection{Training Methodology}

The dataset of 91 optimal points was split 80/20 into training (73 points) and test sets (18 points) using stratified sampling to ensure power range coverage. Both models were trained on identical data for fair comparison.

\textbf{Random Forest Training:} The multi-output regressor was trained in a single call, leveraging sklearn's native support for multi-target regression. Training completed in $<$2 seconds on CPU with automatic parallelization (\texttt{n\_jobs=-1}).

\textbf{SVR Training:} Each of the four output parameters required a separate SVR model due to sklearn's single-output limitation. The scaler was fit once on training data and applied consistently to all models. Total training time: $\sim$5 seconds for all four models.

\textbf{Performance Metrics:} Both models were evaluated using:
\begin{itemize}
    \item \textbf{Coefficient of Determination (R$^2$):} Measures prediction quality (1.0 = perfect, $<$0 = worse than mean baseline)
    \item \textbf{Mean Absolute Error (MAE):} Average prediction deviation in original units
    \item \textbf{Mean Squared Error (MSE):} Penalizes large errors quadratically
\end{itemize}

The evaluation code:
\begin{verbatim}
from sklearn.metrics import r2_score, 
    mean_absolute_error

y_pred = model.predict(X_test)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
\end{verbatim}

\subsection{Comparative Performance Analysis}

\begin{table}[htbp]
\caption{Random Forest vs SVR Performance Comparison (Test Set)}
\centering
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Output} & \multicolumn{2}{c}{\textbf{Random Forest}} & \multicolumn{2}{c}{\textbf{SVR}} & \textbf{Winner} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
& \textbf{R$^2$} & \textbf{MAE} & \textbf{R$^2$} & \textbf{MAE} & \\
\midrule
$D_0$ & 0.686 & 0.042 & 0.401 & 0.054 & RF \\
$D_1$ & -0.262 & 0.150 & -0.204 & 0.090 & SVR \\
$D_2$ & 0.589 & 0.052 & \textbf{0.930} & \textbf{0.040} & \textbf{SVR} \\
$I_{rms}$ & \textbf{0.985} & 0.314 & \textbf{0.986} & 0.386 & Tie \\
\midrule
Model Size & \multicolumn{2}{c}{2.6~MB} & \multicolumn{2}{c}{13~KB} & \textbf{SVR} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{ml_comparison.png}
\caption{Predicted vs actual values for both Random Forest and SVR models. SVR shows superior $D_2$ correlation while both excel at $I_{rms}$ prediction.}
\label{fig_ml_comparison}
\end{figure}

\subsection{Model Deployment}

\subsection{Model Deployment}

Both models were serialized using \texttt{joblib} for dashboard integration:

\begin{verbatim}
import joblib

# Save Random Forest
joblib.dump(rf_model, 
            'tps_rf_model.pkl')

# Save SVR models and scaler
joblib.dump(svr_scaler, 'svr_scaler.pkl')
for name, model in svr_models.items():
    joblib.dump(model, 
                f'svr_model_{name}.pkl')
\end{verbatim}

Random Forest produces a single 2.6~MB file containing all 300 trees and 4 output regressors. SVR generates five files: one scaler (623 bytes) and four model files (3.1--3.3~KB each), totaling 13~KB—a 200$\times$ size reduction.

For smooth visualization, interpolated lookup tables were generated by evaluating each model at 100 evenly-spaced power points (100--1000~W):

\begin{verbatim}
power_range = np.linspace(100, 1000, 100)
predictions = model.predict(
    power_range.reshape(-1, 1))
df_interp = pd.DataFrame({
    'Power_W': power_range,
    'D0': predictions[:, 0],
    'D1': predictions[:, 1],
    'D2': predictions[:, 2],
    'Irms_A': predictions[:, 3]
})
df_interp.to_csv(
    'rf_interpolated_lookup_table.csv',
    index=False)
\end{verbatim}

These CSV files enable instant plotting without runtime inference overhead.

\section{Interactive Dashboard Development}

\subsection{Technology Stack}

The real-time control dashboard was implemented using:
\begin{itemize}
    \item \textbf{Framework:} Streamlit 1.51.0 (Python web framework)
    \item \textbf{Visualization:} Plotly 6.4.0 (interactive charts)
    \item \textbf{ML Inference:} scikit-learn, joblib
    \item \textbf{Data Processing:} pandas, numpy
    \item \textbf{Deployment:} Local server (localhost:8501)
\end{itemize}

\subsection{Dashboard Features}

The dashboard provides four main functional areas implemented in 442 lines of Python code:

\textbf{1. Model Selection Interface:}
\begin{verbatim}
model_choice = st.sidebar.radio(
    "Select ML Model:",
    ["Random Forest", "SVR"]
)
if model_choice == "Random Forest":
    predictions = rf_model.predict(
        [[power_input]])[0]
else:
    X_scaled = svr_scaler.transform(
        [[power_input]])
    predictions = [
        svr_d0.predict(X_scaled)[0],
        svr_d1.predict(X_scaled)[0],
        svr_d2.predict(X_scaled)[0],
        svr_irms.predict(X_scaled)[0]
    ]
\end{verbatim}

Users toggle between models via radio buttons. The dashboard dynamically loads the appropriate model and updates all visualizations instantly.

\textbf{2. Three-Way Comparison Table:}
\begin{verbatim}
comparison_df = pd.DataFrame({
    'Parameter': ['D0', 'D1', 'D2', 
                  'Irms (A)'],
    model_choice: [d0_pred, d1_pred, 
                   d2_pred, irms_pred],
    other_model: [d0_other, d1_other, 
                  d2_other, irms_other],
    'Optimal (Lookup)': [d0_opt, d1_opt,
                         d2_opt, irms_opt]
})
st.dataframe(comparison_df)
\end{verbatim}

The table displays predictions from both ML models alongside ground-truth optimal values, enabling direct performance assessment.

\textbf{3. Interactive Trend Visualizations:} Plotly line charts show how each parameter varies across the full power range (100--1000~W). Users can zoom, pan, and hover to inspect specific values. Charts update automatically when switching models.

\textbf{4. Model Performance Metrics:} Sidebar displays test R$^2$ and MAE for the selected model, providing transparency about prediction accuracy for each output parameter.

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{dashboard_screenshot.png}
\caption{Dashboard interface showing model selection, three-way comparison table, and interactive parameter trend visualizations. Users can switch between RF and SVR in real-time.}
\label{fig_dashboard}
\end{figure}

\section{System Integration and Workflow}

\begin{figure}[htbp]
\centering
\begin{verbatim}
┌─────────────────────────────────────┐
│  1. OPTIMIZATION ENGINE             │
│  (integrated_optimizer.py)          │
│  • Multi-mode grid search           │
│  • 91 optimal points generated      │
│  Output: lookup table (CSV)         │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│  2. MACHINE LEARNING TRAINING       │
│  (train_tps_regressor.py)           │
│  • Random Forest training           │
│  • Model validation & visualization │
│  Output: tps_rf_model.pkl           │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│  3. INTERACTIVE DASHBOARD           │
│  (dashboard.py)                     │
│  • Real-time predictions            │
│  • Interactive visualizations       │
│  • User-friendly interface          │
└─────────────────────────────────────┘
\end{verbatim}
\caption{System Integration Workflow}
\end{figure}

\section{Validation and Verification}

\subsection{Optimization Accuracy Verification}

All 91 optimal points were validated by comparing computed power against target values. The validation script verifies both power accuracy and constraint satisfaction:

\begin{verbatim}
for idx, row in df.iterrows():
    mode = int(row['Mode'])
    d0, d1, d2 = row['D0'], row['D1'], 
                 row['D2']
    
    # Recompute power
    P_computed = power_functions[mode](
        d0, d1, d2, V1, V2, L, T)
    P_target = row['Power_Target_W']
    error = abs(P_computed - P_target)
    
    # Check constraints
    valid = constraint_functions[mode](
        d0, d1, d2)
    
    assert error < 2.0, f"Power error 
        {error}W exceeds tolerance"
    assert valid, f"Point violates 
        Mode {mode} constraints"
\end{verbatim}

Results confirm 100\% constraint satisfaction and power error $<$2~W for all points. The mean error of 1.19~W represents 0.12--1.19\% relative error across the power range, demonstrating excellent optimization accuracy.

\subsection{Machine Learning Model Validation}

Cross-validation was performed using 5-fold stratified splits to assess model generalization. The Random Forest showed consistent performance across folds (R$^2$ std dev $<$0.03), indicating robustness to dataset variations. SVR exhibited slightly higher variance (std dev $\sim$0.05) due to sensitivity to training set composition.

\textbf{Prediction Error Analysis:} We analyzed prediction errors across the power range to identify systematic biases:

\begin{verbatim}
errors = y_test - y_pred
plt.scatter(X_test, errors[:, 2])
plt.xlabel('Power (W)')
plt.ylabel('D2 Prediction Error')
plt.axhline(y=0, color='r', 
            linestyle='--')
\end{verbatim}

Random Forest shows larger errors near mode transition boundaries (e.g., 130~W, 400~W) where duty cycles change abruptly. SVR's smooth interpolation reduces these discontinuity errors, explaining its superior $D_2$ performance.

\textbf{Feature Importance:} Random Forest's built-in feature importance confirms that power is the sole relevant predictor (importance = 1.0), validating our single-input model architecture. Attempts to add polynomial features ($P^2$, $\sqrt{P}$) yielded negligible performance gains ($<$0.01 R$^2$ improvement).

\subsection{Dashboard Functionality Testing}

User interface validated: smooth slider operation, input validation, multi-browser compatibility, chart interactivity (zoom, pan, hover). Performance verified: model loading $<$1~s, prediction latency $<$50~ms, no memory leaks. Edge cases handled: boundary values (100~W, 1000~W) predict correctly, model switching instantaneous, graceful error handling for missing files.

\subsection{Comparative Analysis}

\begin{table}[htbp]
\caption{Performance Comparison Across Approaches}
\centering
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \textbf{$I_{rms}$@100W} & \textbf{Accuracy} & \textbf{Speed} & \textbf{Size} \\
\midrule
SPS & 12.5~A & Poor & Fast & --- \\
SLSQP & 7.39~A & Moderate & Slow & --- \\
\textbf{RF (Ours)} & \textbf{0.086~A} & Excellent & \textbf{$<$50~ms} & 2.6~MB \\
\textbf{SVR (Ours)} & \textbf{0.086~A} & Excellent & \textbf{$<$50~ms} & \textbf{13~KB} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Current Limitations:}
\begin{enumerate}
    \item \textbf{$D_1$ Prediction:} Both RF and SVR show negative test R$^2$ due to discrete mode transitions. Future work: mode-specific regressors or classification-then-regression approach.
    \item \textbf{Offline Optimization:} Grid search requires $\sim$2~s/point, unsuitable for real-time parameter adaptation. ML inference ($<$50~ms) addresses prediction speed but not retraining.
    \item \textbf{Fixed Parameters:} Assumes constant $V_1$, $V_2$, $L$, $f$. Extension to multi-input models needed for voltage-varying applications.
\end{enumerate}


\section{Conclusions}

\begin{enumerate}
    \item \textbf{Exhaustive Multi-Mode Optimization:} 91 optimal points (100--1000~W) with $<$2~W error, achieving 85.9 times improvement over gradient methods at 100~W.
    \item \textbf{Dual Machine Learning Implementation:} Random Forest (R$^2$ = 0.985 for $I_{rms}$, better $D_0$) and SVR (R$^2$ = 0.930 for $D_2$, 200* smaller size) provide complementary strengths for flexible deployment.
    \item \textbf{Interactive Comparison Dashboard:} First TPS control interface enabling real-time model switching, three-way comparison (RF | SVR | Optimal), and performance visualization.
    \item \textbf{Deployment Flexibility:} SVR's compact footprint (13~KB) enables embedded implementation while RF's simplicity suits desktop applications—both achieve $<$50~ms inference.
    \item \textbf{Extensible Architecture:} Modular framework supports multi-level converters, additional ML algorithms, and multi-parameter inputs.
\end{enumerate}

This work demonstrates that machine learning effectively captures complex non-linear TPS relationships while enabling real-time control on modest hardware. The dual-model approach reveals important trade-offs: RF excels at $D_0$ prediction and single-file deployment, while SVR achieves superior $D_2$ accuracy with minimal memory footprint. Both models achieve excellent $I_{rms}$ prediction (R$^2$ $>$ 0.985), the critical metric for efficiency optimization.

Our implementation bridges theoretical optimal control and practical deployment, establishing a foundation for intelligent power electronics with clear pathways to multi-level topologies, adaptive learning, and multi-objective optimization.

\begin{thebibliography}{9}
\bibitem{b1} A. Tong, L. Hang, G. Li, Y. Guo, Y. Zou, J. Chen, J. Li, J. Zhuang, and S. Li, "Power flow and inductor current analysis of PWM control for Dual Active Bridge converter," 2016 IEEE 8th International Power Electronics and Motion Control Conference (IPEMC-ECCE Asia), Hefei, China, 2016, pp. 64-69, doi: 10.1109/IPEMC.2016.7512270.
\bibitem{b4} H. Qin and J. W. Kolar, "Design and Experimental Investigation of a Bidirectional Dual-Active-Bridge DC-DC Converter With A WBG GaN-Device-Based High-Frequency-Link," IEEE Journal of Emerging and Selected Topics in Power Electronics, vol. 4, no. 4, pp. 1256--1273, Dec. 2016.
\bibitem{b5} R. W. De Doncker, D. M. Divan, and M. H. Kheraluwala, "A three-phase soft-switched high-power-density DC/DC converter for high-power applications," IEEE Transactions on Industry Applications, vol. 27, no. 1, pp. 63--73, Jan.--Feb. 1991.
\bibitem{b6} L. Breiman, "Random Forests," Machine Learning, vol. 45, no. 1, pp. 5--32, 2001.
\bibitem{b7} F. Pedregosa et al., "Scikit-learn: Machine Learning in Python," Journal of Machine Learning Research, vol. 12, pp. 2825--2830, 2011.
\bibitem{b8} C. Cortes and V. Vapnik, "Support-vector networks," Machine Learning, vol. 20, no. 3, pp. 273--297, 1995.
\bibitem{b9} G. G. Oggier, G. O. Garc\'ia, and A. R. Oliva, "Modulation strategy to operate the dual active bridge DC-DC converter under soft switching in the whole operating range," IEEE Transactions on Power Electronics, vol. 26, no. 4, pp. 1228--1236, Apr. 2011.
\end{thebibliography}

\end{document}